created at 2022/07/09, 14:07 

<h1>Content</h1>

* TOC
{:toc}
## 摘要

哥德尔证明的巧妙性，进行了转换，发展出新的概念

可计算性 computability theory

## 引言

P对NP问题(P versus NP problem)考虑的是计算机在执行某些类型的任务时可以达到怎样的有效程度。解决这个问题，你并不需要很多的专业知识，你需要的仅仅是想象力。



> 计算机的产生于对”可计算性“这一数学概念的理论性研究，而这种理论研究比计算机技术早15年以上。

20世纪30年代，几位数学家在很大程度上各自独立地开始研究“可计算性”的概念——计算到底**是**什么？从自然数到自然数的函数中哪些是可以计算的？这项研究在现代计算技术成形之前很久就开始了，而且，事实上最初的数学兴趣完全不是由任何要进行实际计算的思想所激发的。人们研究这个问题是由于它内在的数学趣味性。

人们对于“可计算性”的研究兴趣是从奥地利科学家哥德尔(Kurt Gödel)在1931年的一项重大发现所引起的，而哥德尔则是为了回应30年前德国数学家希尔伯特提出的一项挑战而有了这项研究。



## 数学的公理化方法与哥德尔不完备定理

19世纪，研究数学的公理化方法取得了成功，并成为当时的主流，这使得希尔伯特大受激励。研究数学的公理化方法是指，你可以这样来开创一个数学分支：先是构建一套基本假设，即公理(axiom)，然后从这套公理出发进行逻辑推导，从而产生出这个数学分支中的所有事实。于是，”能从公理出发而得到证明的东西“就被认为是”真理“。

> 这种数学观点最早由古希腊数学家泰勒斯(Thales)于公元前700年前后提出的，它形成了古希腊数学的基础。例如，欧几里得在公元前350年前后写成的著作《几何原本》中，就是通过首先列出5条基本公理，然后从这些真理出发推导出所有的定理(几何事实)来阐述几何学。这样构建起来的几何学也被称为欧氏几何(Euclidean geometry)。

这种方法的成功与否，在于是否能够把**构建公理**这件事干得很出色。一个数学陈述(即**命题**)要有资格成为一条可接受的公理，它应该相对简单，简单得十分理想，还要足够基本，基本得”显然成立“(即公理是用来推导其他命题的起点，不能被其他公理推导出来，否则它就不是起点本身，而是能够从起点得出的某种结果)。

这件事情并不总是容易做到。欧氏几何的几何公理系统就引起了人们数百年的争论，争论的焦点在于其中的一条公理——平行公设。许多批评者认为这条公理太过复杂，因而不能取做公理。许多世纪以来，人们试图从**更为基本的假设**出发推出它。事实上，确实有数学家用其他公理代替了平行公设，从而构建出各种”**非欧几何**“。

> **平行公设**
>
> 若两条直线都与第三条直线相交，并且在同一边的内角之和小于两个直角和，则这两条直线在这一边必定相交。
> The parallel postulate: That, if a straight line falling on two straight lines make the interior angles on the same side less than two right angles, the two straight lines, if produced indefinitely, meet on that side on which the angles are less than two right angles. [XX]
>
> 如果从欧式几何公理体系中去掉平行公设，则可以得到更一般的几何，即**绝对几何**。

但是，**我们很难知道自己是否把所有需要的公理都写出来了**。事实上，欧几里得就漏掉了一些研究几何时所需要的细微但是关键的假设，而且这些假设在《几何原本》到处使用。直到19世纪后期，希尔伯特进行了一次严密的考察，才建立起了一套完整的几何公理(Hilbert’s axiom)。

> Hilbert's axioms are a set of 20 assumptions proposed by David Hilbert in 1899 in his book *Grundlagen der Geometrie* (tr. The Foundations of Geometry) as the foundation for a modern treatment of Euclidean geometry [XX].

在成功地为欧几里得构建了一套合适的公理之后，希尔伯特提出，对于数学的任何其他分支都能够——也应该——同样做这种事情。为数学的各个分支分别寻求一套公理，这一想法后来也被成为希尔伯特计划。

希尔伯特计划本身其实隐含着一种假设：**在理论上，对于数学的任何领域，都可以写出一套公理，之后这个数学分支中的所有事实都可以基于这个公理体系推导出。**然而，这个假设成立吗？数学领域的所有分支都可以这样做吗？

1931年，哥德尔的工作给出了否定的答案：这个假设并不成立。他<u>证明</u>了在数学的任何包含初等算术的部分，不论你写出多少条公理，总会存在一些正确的陈述无法从这些公理出发得到证明。这个证明彻底颠覆了希尔伯特计划的结果，被称为哥德尔不完备定理(Gödel's incompleteness theorems)。**数学中的情形与生活中的情形一样，有一部分真理注定要永远保持让人难以捉摸的状态**。

>**Gödel's incompleteness theorems** [XX]https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems
>
>Gödel's incompleteness theorems are two theorems of mathematical logic that are concerned with the limits of provability in formal axiomatic theories.
>
>The first incompleteness theorem states that no consistent system of axioms whose theorems can be listed by an effective procedure (i.e., an algorithm) is capable of proving all truths about the <u>arithmetic of natural numbers</u>. For any such consistent formal system, there will always be statements about natural numbers that are true, but that are unprovable within the system. The second incompleteness theorem, an extension of the first, shows that the system cannot demonstrate its own consistency.

哥德尔的证明过程展示了如何将关于可证明性(provability)的问题转化为与之等价的关于某种从自然数到自然数的函数的可计算性(arithmetic of natural numbers)的问题。（这也是为什么他的定理只适用于数学中那些**包含某种运算**的部分。那些数学领域所基于的公理得让人们能够进行这种算数的操作）他证明了在**任何公理化体系**中，总存在一些函数，它们在这个系统中是不可计算的。在这个工程中，他构建了一种关于”可计算函数(computable function)“概念的形式理论。

在哥德尔工作的基础上，其他一些数学家开始研究可计算性的概念，试图搞清楚那些函数是可计算的，哪些不是。事实上，没有人关注进行实际的计算，也不涉及具体的数，这是一项关于什么样的计算**在原则上**可以进行的纯理论的研究。

以事后的眼光，看到有数学家克林(Stephen Kleene)、图灵(Alan Turing)等人证明的定理，早在可编程计算机产生之前很久就在理论上建立了制造这种东西的可能性，着实令人感叹。20世纪30年代及40年代初建立的理论构想，在40年代和50年代的计算机早期发展中起到了重大作用；而那些从事这种理论研究的数学家，特别是图灵和冯·诺依曼（John von Neumann），在这种新技术的发展中起到了举足轻重的作用。

但之后，当研究出导致计算机诞生的数学理论，并且协助建造出了世界上第一台计算机并为其设计了程序之后，数学家却在很大程度上对他们大脑中的产物失去了兴趣。原因也很简单，因为**之后的大多数工作并不是真正意义上的数学**。

**如何借助计算机帮助解决数学问题？**总还是有一些数学家一开始就对这样的问题十分感兴趣，而且由于计算机技术而产生了许多新的数学分支——包括<u>数值分析</u>、<u>逼近论</u>、<u>计算数论</u>和<u>动力系统理论</u>。还有一些数学家抱着一种**改进实体计算机使用方式**的观点来研究计算的概念。一些早期这样的研究也导致产生了计算机科学中的新学科——也是数学的分支学科，如<u>形式语言理论</u>、<u>算法理论</u>、<u>数据库理论</u>、<u>人工智能</u>和**<u>计算复杂性</u>**。而正是在最后一个学科中出现了**N对NP问题**，而在把这个问题确立为**理论计算机科学**中显要问题的过程中做出最大贡献的，是一名叫库克(Stephen Cook)的美国青年。



## 库克与NP完全性

1939年，库克(Stephen Cook)出生于纽约州的布法罗，1957年进入密歇根大学学习电机工程。但大学第一年，库克选了一门计算机编程课程，并深深沉迷其中，于是库克开始主修数学，并选修了密歇根大学开设的所有与计算机有关的课程。图灵对停机问题(Halting problem)的解答使他特别感兴趣。

> **Halting problem** [XX] https://en.wikipedia.org/wiki/Halting_problem
>
> In computability theory, the halting problem is the problem of determining, from a description of an arbitrary computer program and an input, whether the program will finish running, or continue to run forever. Alan Turing proved in 1936 that a general algorithm to solve the halting problem for all possible program-input pairs **cannot** exist.

1961年，库克从密歇根大学毕业后，去哈佛大学攻读数学博士学位。1966年，他完成了他的博士毕业论文后，在加利福尼亚大学伯克利校区谋得了一个职位，并在那儿呆了四年。1970年，他来到多伦多大学，一年后，发表了名为《定理证明过程的复杂性》（The Comlexity of Theory Proving Procedures）的论文，其中介绍了他新发现的一个理论概念，即NP完全性（NP-completeness）。由于这个发现，库克很快被选为加拿大皇家学会会员和美国科学院院士。

NP完全性的概念为**复杂性理论**研究者提供了一个分析计算任务的强大工具。虽然库克在他1971年的论文中只是证明了一个极其人为且晦涩难懂的**命题逻辑问题**是NP完全的（因此几乎肯定不能在计算机上有效解决），但是不出几个月，加利福尼亚大学伯克利校区的卡普（Richard Karp）就证明了另外的21个问题是NP完全的，**其中包含一些与工业生产有重大厉害关系的极其实际的问题**。自那以后，NP完全问题表扩展到了几百个，或许已到达了几千个，**其中包含了几乎所有的工业界最为关心的计算问题**。所有这些情况，库克本人也感到意外，他在许多年后说到：“我当初认为NP完全性是一个有趣的想法，但我完全没意识到它的潜在冲击力。”



## 旅行商问题(TSP)

**旅行商问题（Travelling salesman problem, TSP）**是计算机科学领域非常著名的问题，它的一般描述形式是：给定一系列城市和每对城市之间的距离，求解访问每一座城市一次并回到起始城市的最短回路。

求解TSP问题的一个朴素的想法，就是列出所有可能的路线的组合，然后对各个路线的总距离进行比较，找到其中的最短路线。但是，在城市数量比较多（甚至不是特别多）的情况下，路线组合的数量会变得相当多，例如，如果我们要访问25个城市，那么一共有
$$
25!=15\ 511\ 210\ 043\ 330\ 985\ 984\ 000\ 000
$$
种组合。计算所有这些路线组合的距离长度，并且进行比较找出最短路线，这是一件非常具有挑战的工作。这个问题看起来很简单，我们所要做的就是把一串串数字加起来的，然后比较这些数字的和，这个问题很难的原因在于**路线数目的超级庞大**。从10个城市增加到11个城市，路线的数目增加了11倍，同样，从11个城市增加到12个城市，路线的数目增加了12倍。因此，虽然增加一个城市看上去很简单，实际上每增加一个城市，路线的数目就要以一个本身在不断增大的倍数往上飞跃。

数学家把以这种方式增长的数学模式，即**其中任何阶段的增长速度与这个阶段的数量大约成正比的模式**，称为呈指数增长(exponential growth)。阶乘数(order multiplier)以指数增长，正是TSP难以解决的根源所在。

朴素的穷举法确实是解决这个问题的一种方法，但是有没有什么更好的方法呢？数学家们同样做出了探索。宽泛地讲，他们的做法可以归为两类。

1. 一种策略是满足于一个近似解。我们不去寻找一条总路线最小的路线，而是去寻找与最佳路线的长度偏差落在一定范围内的路线（比如说5%）。

2. 另一种策略是寻求一个准确的解答。我们可以全面考察这些城市的地理情况，从而设法利用这些城市的布局特点，以减少必须考查的可能的路线的数目。当你面对一组特定的城市时，**认为值得付出相当的努力**去试图找出一个解答时，一个考虑地理因素的方法是有意义的。但是这种方法有个明显的缺点，就是我们得到的解答只适用于这组特定的目的地，增加或减少一个城市，就得重新再来。并且，如果想要使这种方法有效，通常需要大量的技巧。

然而，如果不考虑近似解，也不考虑对一些特定的城市组合求解，那么实际情况就是没有人知道TSP的实用解答。也就是说，**迄今已知的解决方法中，没有一个明显好于穷举法**。而正如我们看到的，除了面对极少量的城市数量以外，**穷举法是不可救药地无效的**。

---



从很大程度上讲，工业领域的数学家为了解决工程中类似的问题进行着徒劳的奋斗，而没过多久，理论工作者——纯粹数学家——也前来予以关注。当纯粹数学家开始思考这个问题时，他们会问一个非常与众不同的问题：**在不考虑近似方法的情况下，是否可以证明对于TSP问题根本不存在有效的解法？**如果能证明这一点，那么你至少知道花费大量的时间、脑力和计算资源来试图解决它是没有意义的。

说有许多聪明人多少年来进行了艰苦的奋斗而结果仍然失败是不够的，或许他们只是还没有找到正确的思路。要使人们相信试图解决这类问题是浪费时间和精力，就必须给出一个扎实可靠的证明，**证明不存在明显好于穷举法的方法可以解决这个问题**。

**从用计算机试图解决一个特定的问题转换到探究用计算机解决问题的方法，这是关于关注点的一个决定性改变**。TSP是一个求出路线的计算任务。理论工作者助手探究的是**一个特定任务用计算机来完成可以达到怎样的有效程度**。

理论工作者首先面对的问题是，找出一个方法来度量在一台计算机上执行一项特定任务需要多长时间。比例如，**求解TSP的最短路线需要多长时间**？很明显，这主要依赖于两样东西：所使用的计算机的算力，和问题中城市的数量。从理论角度讲，问题的关键在于后者。

很明显，一个问题所具有的数据越多，花费在计算的时间也就越长。**但是长多少呢？**准确地说，**如果数据总量增加了一个确定的数量，计算时间会增加多少呢？**比如，将数据总量翻一番，计算时间是会翻一番，还是增加三倍，还是增加十倍，还是增加到惊人的数量？

我们关注的是计算时间相应的增长，因此实际上的计算时间是多少是无关紧要的。==在这种情况下，我们只需要能清楚这个计算所涉及的基本步骤有多少，这就把问题从度量时间转换为对基本步骤计数了。==

**什么是一个基本步骤？**









## 运筹学

---

> 定义
>
> 在计算复杂性理论中，优化问题是指一个由目标函数和约束条件符合某种特殊结构的无穷多个实例（instances）构成的集合所对应的一般性的数学模型。

根据上述定义，虽然有时称类似
$$
\begin{align}
\min\ 2x_2+4x_2\notag \\
s.t.\ 12x_1+x_2&\ge29\notag\\
x_1+x_2&\le10\notag\\
x_1,x_2&\ge0\label{instance}
\end{align}
$$
的例子为一个“优化问题”，但是，更严格地讲，他只能看成一个具备特定决策变量、目标函数和约束条件的线性规划问题的实例。也就是说，线性规划问题一个**优化问题**，而式$\eqref{instance}$只是线性规划问题的一个**实例**。

在面对一个实例时，研究分析人员通常面临的挑战是：**如何选择最有效的算法对相应的模型进行求解？**而在回答这个问题之前，为了避免徒劳的努力，我们首先需要回答：优化问题有很多种分类，**是否所有的优化问题都存在最有效的算法？应该如何识别哪些优化问题可以通过有效而特别精确的算法进行快速求解？**

在20世纪70年代建立起关于优化问题的复杂性理论之前，研究者和分析人员只能凭借经验和直觉选择合适求解给定问题的算法。而计算复杂性理论，提供了一个非常严谨但仍有待进一步完善的定量分析方法，可以用于界定最优化的复杂性程度，并指导选择合适的算法。

在之前讨论TSP时可以看到，随着实例规模的不断增加，需要耗费的计算水平也在不断增加。因此，可以基实例规模定义算法的有效性。



有两个重要的点：如何定义实例规模？以及如何定义算法计算时长随实力规模增大的程度？

于是引申出时间复杂度和实例规模的定义。





---

### 可解问题的多项式时间检验标准

**对于大多数优化问题，分析算法的时间复杂度和度量实例的规模对确定最有效的求解方法会非常有益**。例如，对于一个优化问题规模为 $n$ 实例，若两个求解算法的时间复杂度分别为 $O(n^2)$ 和 $O(n^3)$ ，那么研究人员就可以优先考虑使用前一种算法。

但是，仅仅知道时间复杂度和实例规模，并不能回答：针对特定优化问题是否存在一种最有效的算法，使得该优化问题可以精确求解。为了回答这个问题，首先需要界定什么是“精确求解”。

> 原理（**完全可解问题的多项式时间验证标准**）
>
> 根据复杂性理论，对于一个优化问题，如果其对应的任意一个实例均可以采用多项式时间算法进行求解，即最差情形时的计算时间是关于实例规模的（实例输入数据的编码长度）的多项式函数（其中，幂为常数），那么这个优化问题就是**完全可解的(well-solved)**。

多项式时间验证标准是计算即先驱图灵对理论计算领域的另一个重要贡献，该标准在20世纪70年代被库克等其他计算机先驱扩展到优化领域。

目前，对于一些特定的优化问题，我们已经了解求解它们的最优算法的多项式时间验证结果。如下表所示：

==所对应的最优算法是什么？==




| 多项式时间可解性 | 可能非多项式时间可解 |
| ---------------- | -------------------- |
| 线性规划         | 整数规划问题         |
| 最小支撑树问题   | 斯坦纳最小树问题     |
| 网络流问题       | 固定费用网络流问题   |
| 线性分配问题     | 二次分配问题         |
| 最大流问题       | 广义分配问题         |
| 二匹配问题       | 三匹配问题           |
| 最短路径问题     | 最长路径问题         |
| 关键路径问题     | 最短完工时间调度问题 |
|                  | 旅行商问题           |
|                  | 独立集问题           |
|                  | 集覆盖问题           |
|                  | 集分割问题           |
|                  | 节点覆盖问题         |
|                  | 背包问题             |
|                  | 0-1问题              |
|                  | 多维背包问题         |
|                  | 投资预算问题         |
|                  | 设施选址问题         |
|                  | 车辆路径问题         |

根据完全可解问题的多项式时间检验标准，我们想要知道：**多项式可解的问题究竟包含了哪些？**虽然这张表说明了许多常见的优化问题（左列）满足多项式时间检验标准，但是更多的优化问题尚未确定（右列）：针对这些问题，当前并没有找到多项式可解的算法，同时，也没有严格的证明它们不存在多项式可解的算法。对于这种不确定性，计算复杂性理论中介绍了一些概念，试图去解决这种不确定性。



---

大多数正式的复杂性理论，只适用于**判定问题（decision problem）**。



to be continued~