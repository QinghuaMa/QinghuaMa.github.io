



# 第1章：贝叶斯定理

## 1.定义

$$
P(H|D) = \dfrac{P(H)P(D|H)}{{P(D)}}
$$
$$P(H)$$​为**先验概率**：即得到新数据**前**某一假设的概率；

$$P(H|D)$$​​​为**后验概率**：即看到新数据（新信息）后，我们所要计算的该假设的概率；

$$P(D|H)$$​为**似然度**：即在该假设下得到的这一数据的概率；

$$P(D)$$​​​为**标准化常量**：即在任何假设下得到这一数据的概率。





## 2.理解贝叶斯定理（哲学上）

- 贝叶斯定理提供了一种从$$P(B|A)$$得到$$P(A|B)$$​​​​的策略：贝叶斯定理适用于解决等式右边的计算要比左边容易的问题。
- 贝叶斯定理提供了一种根据数据集D的内容变化更新假设概率H的方法。这种对于贝叶斯定理的理解被称为“**历时诠释**”。”**历时**“意味着某些事情随着时间而变化，即假设的概率随着看到的新数据而变化。
- 从形式上看，贝叶斯公式平淡无奇，它不过是条件概率与全概率公式的简单推论，它之所以出名，在于其现实乃至哲理意义的解释。先验概率$$P(H)$$​​​​​​​是在没有进一步信息（不知道事件D是否发生）的情况下，人们对于事件H可能性大小的认识。当已经知道新的信息（知道D发生）后，人们对于事件H发生的可能性大小有了新的估计。如果把事件D当作“结果”，而把事件H当作原因，那么贝叶斯公式的作用就在于“**由结果推断原因**”：当一个结果已经发生了，在众多可能的“原因”中，到底是哪一个导致了这个结果？这是一个在日常生活和科学技术中常常要问到的问题。<u>在统计学中，是依靠收集的数据（相当于事件D）去寻找所感兴趣的问题的答案，这是一个“**由结果找原因**”性质的过程，故而贝叶斯公式有用武之地。事实上，依靠这个公式的思想发展出了一整套统计推断方法，叫做“**贝叶斯统计**”</u>。





## 3.解题步骤

1）找到新获取的信息（D，data）；

2）枚举**所有**假设（H，Hypothesis）；

3）设计表格。





## 4.实例

### 4.1 曲奇饼问题

假设有两碗曲奇饼：

碗1中，有30个香草曲奇饼，10个巧克力曲奇饼；

碗2中，有20个香草曲奇饼，20个巧克力曲奇饼。

假设在不看的情况下，随机挑一个碗中拿出一块曲奇饼，最后得到了一块香草曲奇饼。

则问：<u>**这块香草曲奇饼是从碗1中取出的概率是多少？**</u>

**信息（D）**：

最终从碗中随机取出的曲奇饼是香草曲奇饼

**假设（H）**：

假设A：取出香草曲奇饼的这个碗是碗1

假设B：取出香草曲奇饼的这个碗是碗2

**贝叶斯公式中各部分含义**：

$$P(H)$$​​​​：在不知道所取曲奇饼种类的情况下，这个饼取自碗1/碗2的概率​；

$$P(D|H)$$​​：在假设A/假设B下，取出香草曲奇饼的概率；

|       | 先验概率$$P(H)$$ | 似然度$$P(D|H)$$ | $$P(H)P(D|H)$$ | 后验概率$$P(H|D)$$​                         |
| ----- | ---------------- | ---------------- | -------------- | ------------------------------------------ |
| 假设A | 0.5              | 0.75             | 0.375          | $$\dfrac{0.375}{0.375+0.25}=\dfrac{3}{5}$$​​​​ |
| 假设B | 0.5              | 0.5              | 0.25           | $$\dfrac{0.25}{0.375+0.25}=\dfrac{2}{5}$$​​​  |

所以，这块香草曲奇饼是从碗1中取出的概率是$$\dfrac{3}{5}$$.

### 4.2 M&M豆问题

M&M豆是有各种颜色的糖果巧克力豆，在1995年

1995年之前：30%褐色，20%黄色，20%红色，10%绿色，10%橙色，10%黄褐色；

1995年之后：24%蓝色，20%绿色，16%橙色，14%黄色，13%红色，13%黄褐色。

假设一个人有两袋M&M豆，一袋是1994年的，一袋是1996年的。但他没有告诉你那个袋子是哪一年的。之后，他从每个袋子中各取出一个M&M豆，一个是黄色的，一个是绿色的。

则问：**<u>黄色的豆来自1994年的袋子的概率是多少？</u>**

**信息（D）**：

他从每个袋子中各取出一个M&M豆，一个是黄色的，一个是绿色的。

**假设（H）**：取出黄色豆的袋子是袋1，取出绿色豆的袋子是袋2.

假设A：袋1是1994年的，袋2是1996年的；

假设B：袋1是1996年的，袋2是1994年的。

|       | 先验概率$$P(H)$$ | 似然度$$P(D|H)$$         | $$P(H)P(D|H)$$            | 后验概率$$P(H|D)$$​                          |
| ----- | ---------------- | ------------------------ | ------------------------- | ------------------------------------------- |
| 假设A | 0.5              | $$0.2\times 0.2=0.04$$   | $$0.5\times 0.04 = 0.02$$ | $$\dfrac{0.02}{0.02+0.007}=\dfrac{20}{27}$$ |
| 假设B | 0.5              | $$0.14\times 0.1=0.014$$ | $$0.5\times 0.014=0.007$$​ | $$\dfrac{0.007}{0.02+0.007}=\dfrac{7}{27}$$ |

所以，黄色豆来自1994年袋子的概率是$$\dfrac{20}{27}$$​​.

### 4.3 Monty Hall问题

#### 4.3.1 原问题

有三扇关闭的大门 ，其中一扇门后面是一辆汽车，另外两扇门后面什么也没有。游戏的目的是要猜那一扇门后面有汽车，如果猜到，那么汽车就是你的。选手首先挑选一扇门A，其他两个门为B和C。在打开你所选的门前，Monty会打开B或C中一个没有车的门来增加悬念。然后Monty会给你一个选择：<u>**是选择最初的选择还是换到剩下的未打开的门**</u>？

**信息（D）**：Monty选择打开B门，后面没有车。

**假设（H）**：==注意是枚举所有假设！！！==

假设A：汽车在门A后；

假设B：汽车在门B后；

假设C：汽车在门C后；

==注意一个前提：此时选手已经选定A门了！！！==

|       | 先验概率$$P(H)$$ | 似然度$$P(D|H)$$ | $$P(H)P(D|H)$$   | 后验概率$$P(H|D)$$                                           |
| :---: | ---------------- | ---------------- | ---------------- | ------------------------------------------------------------ |
| 假设A | $$\dfrac{1}{3}$$ | $$\dfrac{1}{2}$$ | $$\dfrac{1}{6}$$ | $$\dfrac{\dfrac{1}{6}}{\dfrac{1}{6}+\dfrac{1}{3}}=\dfrac{1}{3}$$ |
| 假设B | $$\dfrac{1}{3}$$ | 0                | 0                | 0                                                            |
| 假设C | $$\dfrac{1}{3}$$ | 1                | $$\dfrac{1}{3}$$ | $$\dfrac{\dfrac{1}{3}}{\dfrac{1}{6}+\dfrac{1}{3}}=\dfrac{2}{3}$$ |

所以在此种情况下，选择C门获奖的概率更高。

#### 4.3.2 问题变形

如果Monty总是倾向于选择门B打开，只有车真正在门B后才会迫不得已地打开门C，则上述表格会变为：

|       | 先验概率$$P(H)$$ | 似然度$$P(D|H)$$ | $$P(H)P(D|H)$$   | 后验概率$$P(H|D)$$                                           |
| :---: | ---------------- | ---------------- | ---------------- | ------------------------------------------------------------ |
| 假设A | $$\dfrac{1}{3}$$ | 1                | $$\dfrac{1}{3}$$​ | $$\dfrac{\dfrac{1}{3}}{\dfrac{1}{3}+\dfrac{1}{3}}=\dfrac{1}{2}$$​ |
| 假设B | $$\dfrac{1}{3}$$ | 0                | 0                | 0                                                            |
| 假设C | $$\dfrac{1}{3}$$ | 1                | $$\dfrac{1}{3}$$ | $$\dfrac{\dfrac{1}{3}}{\dfrac{1}{3}+\dfrac{1}{3}}=\dfrac{1}{2}$$​ |

所以，在此种情况下，无论是否选择换门获奖的概率都是一样的。

#### 4.3.3 总结

从这个问题可以看出，贝叶斯定理的确是“**历时诠释**”的：

1）当什么信息也没有时，直接选择并且开门，则中奖概率为$$\dfrac{1}{3}$$;

2）如果Monty打开B门，后面什么也没有，则获取这个信息后，换门中奖概率更高；

3）如果进一步得知Monty总是倾向于打开B门，则得知这个信息后，则无论是否选择换门获奖的概率都是一样的。

从解决这个问题的过程中，似乎也可以看到一丝==**博弈论**==的味道。比如说如果Monty可以说我总是倾向于选择B门，但实际上是随机选的，如果选手真的信了，则中奖的概率就<u>可能</u>会降低。但是，如果选手始终选择换门，则Monty给出的这个干扰信息就是无用的。



# 第4章：估计进阶

## Beta分布

### 意义

Beta分布（Beta Distribution) 是一个<u>作为**伯努利分布**和**二项式分布**的共轭先验分布的密度函数</u>，在机器学习和数理统计学中有着重要应用。在概率论中，Beta分布也成为B分布，是指一组定义在(0,1)区间的连续概率分布。

### 概率密度函数

$$
f(x;\alpha,\beta)=\dfrac{x^{\alpha-1}(1-x)^{\beta-1}}{\int^{1}_{0}u^{\alpha-1}(1-u)^{\beta-1}du}=\dfrac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}
$$

其中，$B(\alpha,\beta)$​​​​是**Beta函数**，也成为B函数，也称为第一类欧拉积分：
$$
B(\alpha,\beta)={\int^{1}_{0}u^{\alpha-1}(1-u)^{\beta-1}du}
$$
当$P>0$，$Q>0$时，Beta函数收敛。

另外，与之有密切联系的有**Gamma函数**$\Gamma(x)$​，是第二类欧拉积分：
$$
\Gamma(x)=\int^{+\infty}_{0}t^{x-1}e^{-t}dt(x>0)
$$
考研时，对它的递归性质有所应用：$\Gamma(x+1)=x\Gamma(x)$​。

另外，Gamma函数和Beta函数有一定联系：

（1）对于任意的正实数P，Q，有关系式：$B(P,Q)=\dfrac{\Gamma(P)\Gamma(Q)}{\Gamma(P+Q)}$​;

（2）$B(P,1-P)=\Gamma(P)\Gamma(1-P)$​。​

### 累积分布函数

$$
F(x;\alpha,\beta)=\dfrac{B_x(\alpha,\beta)}{B(\alpha,\beta)}=I_x(\alpha,\beta)
$$

其中，$B_x(\alpha,\beta)$是不完全B函数，$I_x(\alpha,\beta)$是正则不完全B函数。

（对其含义没有深入理解）​

### 性质

参数为$\alpha$，$\beta$的Beta分布的性质：

1）众数：$\dfrac{\alpha-1}{\alpha+\beta-2}$;

2）期望：$\mu=E(X)=\dfrac{\alpha}{\alpha+\beta}$;

3）方差：$Var(x)=E(X-\mu)^2=\dfrac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$​；

4）偏度：$\dfrac{E(X-\mu)^3}{[E(X-\mu)^2]^{\dfrac{3}{2}}}=\dfrac{2(\beta-\alpha)\sqrt{\alpha+\beta+1}}{(\alpha+\beta+2)\sqrt{\alpha\beta}}$​;

5）峰度：$\dfrac{E(X-\mu)^4}{[E(X-\mu)^2]^2}-3=\dfrac{6[\alpha^3-\alpha^2(2\beta-1)+\beta^2(\beta+1)-2\alpha\beta(\beta+2)]}{\alpha\beta(\alpha+\beta+2)(\alpha+\beta+3)}$​，注意：减去3是因为峰度以标准正态分布的图像为标准的。

## 共轭先验分布

在贝叶斯统计中，如果后验分布与先验分布属于**同类**，则先验分布与后验分布被称为**共轭分布**，而先验分布被称为似然函数的**共轭先验**。

（比如：似然函数是伯努利分布，先验分布和后验分布都是Beta分布，则就可以说：<u>**Beta分布**叫做**伯努利分布**的**共轭先验**</u>。

先验分布——Beta分布

似然函数——二项式似然函数

后验分布——Beta分布

Beta分布的两个参数又叫超参数，因为Beta分布好似是伯努利分布的分布，可以通过不断迭代更新超参数，生成更好的伯努利分布或二项分布。超参数相当容易迭代，因为先验和后验是一个形式。https://www.cnblogs.com/bonelee/p/14329635.html）

共轭先验的好处主要在于<u>代数计算上的便利性</u>，可以直接给出后验分布的封闭形式，否则的话只能数值计算。共轭先验也有助于获得关于似然函数如何更新分布的直观印象。比如说网上用Beta分布算棒球击球率的那张图（https://blog.csdn.net/a358463121/article/details/52562940）。

**所有的指数家族的分布都有共轭先验**。

指数族分布：正态分布、两点分布、二项分布、泊松分布、伽马分布。

## 代码优化

书中从P31页开始对原始代码进行优化，以提高代码运行和效率。

### （1-1）减少归一化次数

从之前比较利于理解的代码可以看到，Update方法每获取一次数据集中的一个数据（信息），就计算一次似然度、以及先验概率和似然度的乘积，之后进行归一化。如果有250个数据，就要归一化250次。所以第一个加速的地方就是每次更新不进行归一化，将没有进行归一化的$P(H)P(D|H)$作为下一次迭代的$P(H)$。等250个数据都利用完，只进行一次归一化即可。这个简化步骤是不影响结果的，因为每次归一化只是将每一行的$P(H)P(D|H)$均除以一个相同的常数$P(D)$而已。

### （1-2）通过改写Likelihood使其处理整个数据集以删去循环迭代

之前的代码每次循环只获取一个数据（信息），要运行250次。但实际上这个过程是在做**n重伯努利试验**。所以如果将整个数据集当作一个整体来看，就可以使用一个二项似然函数计算整个数据集出现的似然概率（Likelihood），便可以避免循环。

### （2）用Beta函数作为先验分布

使用Beta函数作为先验分布有以下优点：

1. Beta分布是定义在从0到1（包括两者）的区间上，所以它是一个描述比例和概率的自然选择。并且，**beta分布可以看作一个概率的概率分布，当你不知道一个东西的具体概率是多少时，它可以给出了所有概率出现的可能性大小。**当参数$\alpha$和$\beta$均取值为1时，Beta分布就退化成定义在[0,1]区间上的连续均匀分布。我们之后的先验分布就令$\alpha=1,\beta=1$​​，虽然也是均匀分布，<u>但是它是连续的</u>，有很好的性质，而之前的均匀分布是离散的。​
2. 由于上面的代码优化2）通过二项式似然函数计算似然度，所以如果使用Beta分布作为先验分布，则最终的后验概率也服从Beta分布。并且如果先验概率是带有参数$\alpha$和$\beta$的Beta分布，则如果我们看到h次正面和t次反面的数据，则后验概率就是参数为（$\alpha+h$）和（$\beta+t$​​​​​）的Beta分布，因此**<u>就可以通过两个加法实现Update方法</u>**，而不再在其中调用Likelihood()方法。
3. 优点2只适用于先验概率分布<u>**的确是**</u>一个Beta分布的情形。但幸运的是，在最低限度上，对许多实际的先验分布Beta分布都可以进行良好的近似，同时可以完美匹配均匀先验。参数$\alpha=1,\beta=1$的Beta分布就是从0到1的均匀分布。

以欧元问题为例，设其先验Beta分布参数为：$\alpha=1,\beta=1$，即假设欧元正面朝上的概率在[0,1]区间上具有等可能性。（这和之前离散的均匀分布一样，都是对没有考虑到“质心会大幅度偏移是一个可能性较小的事件“。不如三角分布有合理。）此时如果看到140次正面，110次反面，则其后验Beta分布的参数为：$\alpha=141,\beta=111$，期望为：$\mu=E(X)=\dfrac{\alpha}{\alpha+\beta}=0.56$​​，这**和之前使用PMF得到的结果相同**：说明“看到140次正面，110次反面”的事件表明，该硬币正面朝上的概率是56%。

上述情况是，**<u>你对先验分布完全没有猜测和感觉</u>**。如果你感觉一块硬币应该没有质心偏移，即投掷100次，应该有50次证明朝上，50次反面朝上。因此设先验Beta分布的参数为：$\alpha=50,\beta=50$。在这种感觉之下，投掷250次硬币看到“140次正面，110次反面”的情况，则后验Beta分布的参数为：$\alpha=190,\beta=160$，期望为：$\mu=E(X)=\dfrac{\alpha}{\alpha+\beta}=0.54$，可以看到两次结果有所差异。

如果以**客观派**的观点来看，如果看到硬币硬币140次正面，110次反面，那么期望为$\dfrac{140}{140+110}=0.56$，和前一次的结果相近。

对比以上两次后验概率的求解：

情况（1）的先验Beta分布：$\alpha=1,\beta=1$

情况（2）的先验Beta分布：$\alpha=50,\beta=50$

两个Beta分布的期望是一样的，那么两者的差异在哪里呢？

$g_1=\dfrac{6[\alpha^3-\alpha^2(2\beta-1)+\beta^2(\beta+1)-2\alpha\beta(\beta+2)]}{\alpha\beta(\alpha+\beta+2)(\alpha+\beta+3)}=\dfrac{-24}{20}=-1.2$​​​

$g_2=\dfrac{6[\alpha^3-\alpha^2(2\beta-1)+\beta^2(\beta+1)-2\alpha\beta(\beta+2)]}{\alpha\beta(\alpha+\beta+2)(\alpha+\beta+3)}=\dfrac{-6}{103}=-0.0583$​​

两者的（以标准正态分布为标准的）峰度是有所差别的，这意味着后者的先验Beta分布在均值0.5处的峰较高。通俗地讲，就是在做重复实验之前，”投掷100次，50次正面，50次反面“的信息比“投掷2次，1次正面，1次反面“更加能够说明“投掷这枚硬币有50%的概率正面朝上”的信仰；而<u>**在不同的信仰坚定程度之下**</u>，看到相同的信息——250次投掷，140次正面，110次反面——得到的后验Beta分布是不同的（期望是不同的）。这大概能够解释什么是<u>**主观派**</u>吧。

但是，如果你有足够多的数据，比如说你投掷了25万次，有14万次正面，11万次反面，那么在这时，基于上述两种不同的先验Beta分布最终算出的后验分布基本上是一致的。因此这就引申出一个观点：<u>**如果两个人开始之前对于先验有不同的信仰，他们通常会发现，==随着更多的数据==，后验分布收敛了。在一些点上，分布之间的差异足够小到没有实际影响**</u>。

（p24、25）

在贝叶斯当中，有两种途径选择先验分布：

1）一些人建议学则对能代表问题相关背景资料的先验分布。在这种情况下，先验被认为是“信息“。问题是，人们可能会使用不同的背景信息（或者是进行不同的诠释）。所以基于信息的先验往往显得主观。（上面投掷硬币的例子就能够解释这一条）

2）另一种方法是所谓的”无信息参考的先验“，其目的是为了让数据说话，越没有约束越好。在某些情况下，你可以选择包含一些期望属性的特殊先验，例如，就估计量设置一个最小先验。（<u>不懂这一条，但是会不会与**信息论**的相关理论产生联系？《纳什均衡与博弈论》</u>）

”无信息先验“的观点似乎更为客观。但通常，我倾向于选择先验信息。理由如下：

1. 贝叶斯分析总是基于模型决策的。选择先验就是决策之一，但它不是唯一的部分，甚至不是最主观的。因此，即使无信息先验较为客观，整个分析本身仍然是主观的。如此以来，选择后者并不会使整个过程都客观，反而会使问题解决变得更复杂；（可不可以认为，贝叶斯分析本身就是一个主观的理论，主观派）
2. 对于大多数实际中的问题，你可能是在两个对立面之间：也许有大量的数据，也许没有。如果有大量数据，先验的选择不是特别关键（上述投掷硬币的例子）：信息先验和无信息先验会得到几乎相同的结果；如果没有太多参考数据，比如说火车头问题，那么采用相关的背景信息（如幂律分布，而不是采用类似”大中小公司数量都相同的分布“）就有很大的区别了。并且比如德国坦克问题，如果必须基于你的结论做出生死存亡的决策，<u>**==你就应该利用所有的信息，而不是在”要保持客观“的幻觉中假装不了解具体情况==**</u>。































# thinkbayes模块定义的方法

PMF对象

Prob方法：获得值和概率。
